#!/usr/bin/perl

##########################################################
##  SHELL FOR END-OF-SENTENCE CLASSIFIER
##
##    hw1a.prl < sent.data.test
##
##  Suggestion: run in a wide window
##########################################################

$L="./classes";

&initialize_set(*abbrevs_,"$L/abbrevs"); 
&initialize_set(*titles_,"$L/titles"); 
&initialize_set(*sentence_,"$L/sentence_internal");
&initialize_set(*timeterms_,"$L/timeterms"); 

##########################################################
## GET_FEATURE_VECTOR - creates a feature vector to be
##                      classified by logistic regression
##
##  The 12-dimensional feature vector consists of (in the
##  order of returned values) the following values: 
##  1. Boolean : R1 indicates new paragraph
##  2. Boolean : R1 is either . or , or ; or -
##  3. Boolean : R1 is a double left quote (``)
##  4. Boolean : R1 consists of digits only
##  5. Boolean : L1 starts in upper case
##  6. Boolean : R1 belongs to 'sentence internal'
##  7. Boolean : R1 belongs to 'title'
##  8. Boolean : R1 belongs to 'abbreviation'
##  9. Boolean : R1 belongs to 'time term'
## 10. Number  : # of words to the left before delimeter
## 11. Number  : # of words to the right before delimeter
## 12. Number  : # of spaces following the period
##
##  The true class label and full line of data are
##  returned along with the feature vector.
##########################################################

sub get_feature_vector() {
    my $line = shift;
    
    @words = split(' ', $_);
    
    my $R1 = $words[6];
    my $L1 = $words[4];
    
    $r1NewPara = $R1 eq "<P>" ? 1 : 0;
    $r1Special = $R1 =~ /[\.,;-]/ ? 1 : 0;
    $r1DoubleQ = $R1 eq "``" ? 1 : 0;
    $r1AllDigit = $R1 =~ /[0-9]+/ ? 1 : 0;
    $l1Upper = $L1 =~ /^[A-Z]$/ ? 1 : 0;
    
    $l1SentInt = &classmember($L1, sentence_) ? 1 : 0;
    $l1Title = &classmember($L1, titles_) ? 1 : 0;
    $l1Abbrev = &classmember($L1, abbrevs_)? 1 : 0;
    $l1Time = &classmember($L1, timeterms_)? 1 : 0;
       
    return ($r1NewPara, $r1Special, $r1DoubleQ, $r1AllDigit, $l1Upper, $l1Title, 
    	$l1Abbrev, $l1SentInt, $l1Time, $words[9], $words[10], $words[11], $words[0], $line);
}

##########################################################
## 
## Performs logistic regression classification for each
## line of data. The coefficients and intercept value 
## were determined using the output of Weka trained model.
##
##########################################################

while (<>) {
    local @feature_vector = &get_feature_vector($_);
    	
    my $logistic_value = 0.0;
    
    # Perform dot-product with coeffcients
    $logistic_value += (7.2115 * $feature_vector[0]);
    $logistic_value += (-3.2753 * $feature_vector[1]);
    $logistic_value += (2.2672 * $feature_vector[2]);
    $logistic_value += (-2.9189 * $feature_vector[3]);
    $logistic_value += (-6.7567 * $feature_vector[4]);
    $logistic_value += (-5.4091 * $feature_vector[5]);
    $logistic_value += (-4.24 * $feature_vector[6]);
    $logistic_value += (-5.8588 * $feature_vector[7]);
    $logistic_value += (1881.8571 * $feature_vector[8]);
    $logistic_value += (0.0012 * $feature_vector[9]);
    $logistic_value += (-0.0004 * $feature_vector[10]);
    $logistic_value += (2.1213 * $feature_vector[11]);
    
    # Add intercept value
    $logistic_value += 1.4238;
    
    my $class = $feature_vector[12];
    my $line = $feature_vector[13];
    
    $probability = 1 / (1 + exp(-$logistic_value));
    
    # Classify according to probability
    if ($probability > 0.5) {
    	&ret($class,'EOS',$line);
    } else {
    	&ret($class,'NEOS',$line);
    }
}

$correct_percentage = ($correct/($correct+$incorrect)) * 100;
$incorrect_percentage = 100 - $correct_percentage;

printf("### HW1A schoi60 - OVERALL CORRECT: %u = %.1f%%    INCORRECT: %u = %.1f%%\n", 
	$correct, $correct_percentage, $incorrect, $incorrect_percentage);
 
##########################################################
## RET - prints full line for errors and keeps score
##     - $where indicates the rule number responsible for the classification
##
##  This is a useful debugging tool, as after each change in
##  the program one can identify the remaining misclassified
##  training examples and the patterns responsible for them. 
##########################################################
 
sub ret {

    my $trueclass  = shift;   # what is the true sentence class ('NEOS','EOS')
    my $givenclass = shift;   # what is the sentence class my rule gives
    my $line       = shift;   # the actual line tested

    if ($trueclass eq $givenclass) {
    	$correct++;
    } else {
    	$incorrect++;
    }
    
    print $givenclass, " ", $line;
}

##########################################################
## CLASSMEMBER - tests for membership of $key in a given set
##
##  The \L in $set{"\L$key"} is a perl hack to convert a
##  string into all lower case for lookup in a word array
##  insensitive to the capitalization of the original key.
##########################################################

sub classmember{
   local($key,*set) = @_;

   return $set{"\L$key"};
}

##########################################################
## INITIALIZE_SET - loads named associative array with set members   
##########################################################

sub initialize_set{
   local(*set,$where) = @_;
   
    open (FILE,$where) || die "Can't open file $where: $!\n";

    while (<FILE>) {
        chop;
        $set{$_} = 1;
    }
    close (FILE);
}